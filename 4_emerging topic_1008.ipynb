{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b28259e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import matutils, models\n",
    "import scipy.sparse\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import re\n",
    "import os\n",
    "import numpy as np\n",
    "import time\n",
    "#from gensim.models.ldamulticore import LdaMulticore\n",
    "### choose the callbacks classes to import\n",
    "#from gensim.models.callbacks import PerplexityMetric, ConvergenceMetric, CoherenceMetric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c56922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "saving_path=\"C:/Users/minha/Desktop/plots_new/updated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6a758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choosing number of topics\n",
    "nTopics = 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f74441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define topic names (11)\n",
    "topic_names = ['Modeling & Forecasting', 'Precipiatation and Extremes', 'Climate Change', 'Urban Risk Management', \n",
    "                   'River Hydraulics',\"Wetland & Ecology\",'Groundwater & Soil Chemistry',\"Geomorphology\",\n",
    "                  \"Soil hydrology\",\"Coastal hydrology\",\"Reservoir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13c537",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5333c2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading necessary inputs for lda from pickle\n",
    "import pickle as pkl\n",
    "\n",
    "with open('pickled_1907/data_lemmatized.pkl', 'rb') as f:\n",
    "    data_lemmatized = pkl.load(f)\n",
    "\n",
    "with open('pickled_1907/cleaned_corpus.pkl', 'rb') as f:\n",
    "    corpus = pkl.load(f)\n",
    "with open(\"pickled_1907/id2word.pkl\", 'rb') as f:\n",
    "    id2word= pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d50b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('pickled_1907/raw_corpus.pkl', 'rb') as f:\n",
    "    corpus_df = pkl.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00f130e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from gensim.models import LdaModel\n",
    "from gensim.models import LdaModel\n",
    "nTopics =11\n",
    "# Load model\n",
    "lda_model = LdaModel.load(f'pickled_1907/trained_models/trained_lda_model_{nTopics}.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e3dbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic distribution\n",
    "distribution_file_name = f'pickled_1907/topic_distribution//topic_distributions_{nTopics}.npy'\n",
    "topic_distributions = np.load(distribution_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9298e4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_distributions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#finding articles per topics\n",
    "#topic = 7\n",
    "#topic_idx = (-topic_distributions[:,topic]).argsort()\n",
    "#corpus_df.loc[topic_idx[:100],'Article Title'].to_csv(f'pickled_1907/investigation/topic_{topic}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce684c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull topics\n",
    "topics = lda_model.show_topics(formatted=False, num_topics=nTopics, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f157e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.unique(corpus_df['Year'])\n",
    "plot_years=[]\n",
    "for y,year in enumerate(years):\n",
    "    hm_year = topic_distributions[corpus_df['Year'] == year,:]\n",
    "    if hm_year.shape[0]>40:\n",
    "        plot_years.append(year)\n",
    "        \n",
    "topic_distributions_by_year = np.zeros([len(plot_years), lda_model.num_topics])\n",
    "for y, year in enumerate(plot_years):\n",
    "    hm_year = topic_distributions[corpus_df['Year'] == year,:]\n",
    "    topic_distributions_by_year[y,:] = np.sum(hm_year, axis=0) / np.sum(hm_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f8ecd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_distributions_by_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc52d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#topic_distributions_by_year[:,3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80625ecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some basic parameters of plotting\n",
    "font = {'family' : \"Arial\",\n",
    "         'weight' : 'normal',\n",
    "         'size'   : 12}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3252f29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_colors = ['steelblue','darkorchid', 'seagreen','slategrey','darkturquoise','tomato','lightcoral',\n",
    "                  'indigo','burlywood','blueviolet','firebrick']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e20e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series dependednt from each other\n",
    "fig, ax1 = plt.subplots(figsize=(12,7))\n",
    "#gs = fig.add_gridspec(1,4)\n",
    "\n",
    "#ax1 = fig.add_subplot(gs[0, :3])\n",
    "for i in range(lda_model.num_topics):\n",
    "    color = topic_colors[i] \n",
    "    pltcolor = color\n",
    "    ax1.plot(plot_years, topic_distributions_by_year[:,i], \n",
    "             c=pltcolor, linewidth=3, label=topic_names[i])\n",
    "ax1.set_xticks(plot_years[::4])\n",
    "ax1.set_xlim([plot_years[0], plot_years[-1]])\n",
    "ax1.set_ylabel('Popularity', fontsize=20)\n",
    "#ax1.set_title('Topic trend', fontsize=28)\n",
    "plt.legend(loc=\"center right\", bbox_to_anchor=(1.40, 0.5),fontsize=14)\n",
    "ax1.grid()\n",
    "plt.savefig(saving_path+\"Topic_trends_ \"+ time.strftime(\"%Y-%m-%d %H%M\") + \".png\",dpi=150,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6081bbaa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot relative time series dependent to each other\n",
    "fig,ax = plt.subplots(figsize=(12,7))\n",
    "#gs = fig.add_gridspec(1,4)\n",
    "\n",
    "#ax1 = fig.add_subplot(gs[0, :3])\n",
    "ax.stackplot(plot_years, topic_distributions_by_year.transpose(),labels=topic_names, colors=topic_colors)\n",
    "# ax1.legend(topic_names, loc='center right', shadow=True)\n",
    "plt.xticks(plot_years[::-1])\n",
    "#plt.set_xlim([plot_years[0], 2022])\n",
    "plt.xticks(rotation=\"vertical\")\n",
    "plt.yticks([])\n",
    "#ax1.set_ylim(0, 1)\n",
    "#ax1.set_ylabel('Popularity', fontsize=16)\n",
    "#plt.title('Topic Activation over time', fontsize=22)\n",
    "plt.grid()\n",
    "\n",
    "#ax0 = fig.add_subplot(gs[0, 3])\n",
    "#ax0.stackplot(plot_years, topic_distributions_by_year.transpose(),labels=topic_names, colors=list(custom_colors.values()))\n",
    "current_handles, current_labels = plt.gca().get_legend_handles_labels()\n",
    "# sort or reorder the labels and handles\n",
    "reversed_handles = list(reversed(current_handles))\n",
    "reversed_labels = list(reversed(current_labels))\n",
    "plt.legend(reversed_handles,reversed_labels,loc='center right', shadow=False, fancybox = True,bbox_to_anchor=(1.40, 0.5),fontsize=14)\n",
    "#plt.legend(topic_names, loc='center right', shadow=True, fancybox = True,bbox_to_anchor=(1.3, 0.5))\n",
    "#ax0.axis('off')\n",
    "plt.savefig(saving_path+\"relative_topic_trends \"+ time.strftime(\"%Y-%m-%d %H%M\") + \".png\",dpi=150, bbox_inches=\"tight\")\n",
    "#plt.savefig(\"C:/Users/minha/Desktop/plots/pic activationtopic_11_2608.jpg\",dpi=300,bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fd6650",
   "metadata": {},
   "source": [
    "### Individual time series plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de1502b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import LdaModel\n",
    "import pickle as pkl\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud \n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b2877a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### emerging topic\n",
    "# calculate time series\n",
    "years = np.unique(corpus_df['Year'])\n",
    "topic_distributions_by_year = np.zeros([len(years), lda_model.num_topics])\n",
    "for y, year in enumerate(years):\n",
    "    hm_year = topic_distributions[corpus_df['Year'] == year,:]\n",
    "    topic_distributions_by_year[y,:] = np.sum(hm_year, axis=0) / np.sum(hm_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d351d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create wordclouds\n",
    "stop_words = stopwords.words('english')\n",
    "cloud = WordCloud(stopwords=stop_words,\n",
    "                  background_color='white',\n",
    "                  width=3500,\n",
    "                  height=3500,\n",
    "                  max_words=15,\n",
    "                  color_func=lambda *args, **kwargs: colorlist[t],\n",
    "                  prefer_horizontal=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "171dd5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pull topics\n",
    "topics = lda_model.show_topics(formatted=False, num_topics=nTopics, num_words=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96f476",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot wordclouds and scaled time series\n",
    "fig = plt.figure(figsize=(12, 18))\n",
    "#fig, ax1 = plt.subplots(ncols=4, nrows=3, constrained_layout=True)\n",
    "gs = fig.add_gridspec(nTopics,1)\n",
    "for t in range(nTopics):\n",
    "    if t < 12:\n",
    "        # plot time series\n",
    "        ax1 = fig.add_subplot(gs[t, 0:])\n",
    "        ax1.plot(years, topic_distributions_by_year[:,t], color=topic_colors[t], linewidth=4)\n",
    "        ax1.set_title(topic_names[t])\n",
    "        ax1.set_xticks(years[4::5])\n",
    "       # ax1.set_ylabel('Popularity')\n",
    "        ax1.grid()\n",
    "    \n",
    "    \n",
    "fig.tight_layout()\n",
    "\n",
    "# Save figure\n",
    "#plt.savefig(saving_path+\"wordclouds_and_trends\"+time.strftime(\"%Y-%m-%d %H%M\")+\".png\",dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
